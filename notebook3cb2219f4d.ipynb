{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Define the main data directory\n# This is where Kaggle stores the dataset you linked\nbase_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\n\n# Define paths for training, validation, and test sets\ntrain_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\n# Define paths for NORMAL and PNEUMONIA images within the training set\ntrain_normal_dir = os.path.join(train_dir, 'NORMAL')\ntrain_pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')\n\n# Get the number of images in each category\nnum_normal_train = len(os.listdir(train_normal_dir))\nnum_pneumonia_train = len(os.listdir(train_pneumonia_dir))\n\nprint(f\"Total training images (NORMAL): {num_normal_train}\")\nprint(f\"Total training images (PNEUMONIA): {num_pneumonia_train}\")\nprint(\"---\")\nprint(f\"Total training images: {num_normal_train + num_pneumonia_train}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:32:30.664942Z","iopub.execute_input":"2025-12-05T17:32:30.665497Z","iopub.status.idle":"2025-12-05T17:32:30.962966Z","shell.execute_reply.started":"2025-12-05T17:32:30.665469Z","shell.execute_reply":"2025-12-05T17:32:30.962223Z"}},"outputs":[{"name":"stdout","text":"Total training images (NORMAL): 1341\nTotal training images (PNEUMONIA): 3875\n---\nTotal training images: 5216\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Let's visualize some of the images\nimport cv2 # A library for image processing\n\n# Get a few sample image file names\nnormal_images = os.listdir(train_normal_dir)[:5]\npneumonia_images = os.listdir(train_pneumonia_dir)[:5]\n\n# Create a figure to display the images\nfig = plt.figure(figsize=(10, 5))\n\n# Plot the NORMAL images\nfor i, img_name in enumerate(normal_images):\n    img_path = os.path.join(train_normal_dir, img_name)\n    img = cv2.imread(img_path)\n    \n    ax = fig.add_subplot(2, 5, i + 1)\n    ax.imshow(img)\n    ax.set_title('NORMAL')\n    ax.axis('off')\n\n# Plot the PNEUMONIA images\nfor i, img_name in enumerate(pneumonia_images):\n    img_path = os.path.join(train_pneumonia_dir, img_name)\n    img = cv2.imread(img_path)\n    \n    ax = fig.add_subplot(2, 5, i + 6)\n    ax.imshow(img)\n    ax.set_title('PNEUMONIA')\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import the necessary tool from TensorFlow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 1. Create a data generator for the training set\n# We will also apply 'data augmentation' here to make our model more robust.\n# Data augmentation creates modified versions of our images (rotated, zoomed, etc.)\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,      # Normalize pixel values to be between 0 and 1\n    rotation_range=20,   # Randomly rotate images\n    width_shift_range=0.1, # Randomly shift images horizontally\n    height_shift_range=0.1,# Randomly shift images vertically\n    shear_range=0.1,     # Apply shear transformation\n    zoom_range=0.1,      # Randomly zoom in on images\n    horizontal_flip=True,# Randomly flip images horizontally\n    fill_mode='nearest'  # How to fill in newly created pixels\n)\n\n# 2. Create a data generator for the validation and test sets\n# We only need to normalize these images, no augmentation needed.\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# 3. Use the generators to load images from their directories\nIMG_SIZE = (150, 150) # Define a standard size for all images\nBATCH_SIZE = 32       # How many images to process at a time\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary' # Since we have two classes (NORMAL, PNEUMONIA)\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary'\n)\n\n# Print out the results\nprint(\"\\nData generators created successfully!\")\nprint(\"Keras has automatically assigned numerical labels to our classes:\")\nprint(train_generator.class_indices)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\n# 1. Load the VGG16 model, pre-trained on ImageNet data\n# We don't include the top (classification) layer because we'll create our own\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\n# 2. Freeze the convolutional base\n# This prevents the weights in VGG16 from being updated during training\nconv_base.trainable = False\n\n# 3. Create our new model on top of the VGG16 base\nmodel = models.Sequential()\nmodel.add(conv_base) # Add the frozen VGG16 base\nmodel.add(layers.Flatten()) # Flatten the output to a 1D vector\nmodel.add(layers.Dense(256, activation='relu')) # Add a new dense layer for our specific task\nmodel.add(layers.Dense(1, activation='sigmoid')) # The final output layer (1 neuron for binary classification)\n\n# 4. Compile the model\n# This configures the model for training\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n              metrics=['accuracy'])\n\n# 5. Print a summary of our model architecture\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model using the data generators\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=100,  # Number of batches to draw from the generator per epoch\n    epochs=10,            # How many times to go through the entire dataset\n    validation_data=validation_generator,\n    validation_steps=50   # Number of batches to draw from the validation generator\n)\n\n# Save the trained model\nmodel.save('pneumonia_classifier_v1.keras')\n\nprint(\"\\nTraining complete and model saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrieve accuracy and loss from the history object\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(1, len(acc) + 1)\n\n# Create a figure with two subplots\nplt.figure(figsize=(12, 5))\n\n# Plot training and validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, 'bo-', label='Training Accuracy')\nplt.plot(epochs_range, val_acc, 'ro-', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot training and validation loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, 'bo-', label='Training Loss')\nplt.plot(epochs_range, val_loss, 'ro-', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We need to build a new model that includes Dropout layers\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\n# Load the base model again\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\n\n# Freeze the base\nconv_base.trainable = False\n\n# Create the new model with Dropout layers\nmc_model = models.Sequential()\nmc_model.add(conv_base)\nmc_model.add(layers.Flatten())\nmc_model.add(layers.Dense(256, activation='relu'))\nmc_model.add(layers.Dropout(0.5)) # <--- ADDED DROPOUT\nmc_model.add(layers.Dense(1, activation='sigmoid'))\n\n# Compile the new model\nmc_model.compile(loss='binary_crossentropy',\n                 optimizer=optimizers.RMSprop(learning_rate=2e-5),\n                 metrics=['accuracy'])\n\n# Print the summary of the new model\nmc_model.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the new model with dropout\nhistory_mc = mc_model.fit(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=10,  # We'll train for the same number of epochs for comparison\n    validation_data=validation_generator,\n    validation_steps=50\n)\n\n# Save the new trained model\nmc_model.save('pneumonia_classifier_mc_v1.keras')\n\nprint(\"\\nTraining of MC model complete and model saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n# This is the core function for Monte Carlo predictions\ndef mc_predict(model, img_path, num_samples=100):\n    \"\"\"\n    Performs Monte Carlo predictions by running the model multiple times with dropout enabled.\n    \"\"\"\n    # 1. Load and preprocess the image\n    img = image.load_img(img_path, target_size=IMG_SIZE)\n    img_tensor = image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor /= 255.  # Normalize the image\n\n    # 2. Create a list to store predictions\n    predictions = []\n\n    # 3. Run prediction N times\n    for _ in range(num_samples):\n        # The 'training=True' flag is the key to activating dropout during prediction\n        pred = model(img_tensor, training=True)\n        predictions.append(pred.numpy().flatten()[0])\n\n    # 4. Calculate mean and standard deviation\n    mean_prediction = np.mean(predictions)\n    std_dev = np.std(predictions)\n\n    return mean_prediction, std_dev\n\n# --- Let's test it on one image ---\n\n# Get a sample image from the validation set (which the model hasn't trained on)\n# You can try both a NORMAL and a PNEUMONIA image to see the difference\nsample_normal_image_path = os.path.join(validation_dir, 'NORMAL', os.listdir(os.path.join(validation_dir, 'NORMAL'))[0])\nsample_pneumonia_image_path = os.path.join(validation_dir, 'PNEUMONIA', os.listdir(os.path.join(validation_dir, 'PNEUMONIA'))[0])\n\n# Perform MC prediction on the NORMAL image\nmean_norm, std_norm = mc_predict(mc_model, sample_normal_image_path)\nprint(f\"--- Prediction for a NORMAL image ---\")\nprint(f\"Predicted Probability (of Pneumonia): {mean_norm:.4f}\")\nprint(f\"Uncertainty (Standard Deviation): {std_norm:.4f}\")\nprint(\"\\n\")\n\n# Perform MC prediction on the PNEUMONIA image\nmean_pneu, std_pneu = mc_predict(mc_model, sample_pneumonia_image_path)\nprint(f\"--- Prediction for a PNEUMONIA image ---\")\nprint(f\"Predicted Probability (of Pneumonia): {mean_pneu:.4f}\")\nprint(f\"Uncertainty (Standard Deviation): {std_pneu:.4f}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This function is similar to the one before, but it returns the raw predictions\ndef get_mc_predictions(model, img_path, num_samples=100):\n    img = image.load_img(img_path, target_size=IMG_SIZE)\n    img_tensor = image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor /= 255.\n    \n    predictions = []\n    for _ in range(num_samples):\n        pred = model(img_tensor, training=True)\n        predictions.append(pred.numpy().flatten()[0])\n        \n    return predictions\n\n# Get the raw predictions for both images\nnormal_preds = get_mc_predictions(mc_model, sample_normal_image_path)\npneumonia_preds = get_mc_predictions(mc_model, sample_pneumonia_image_path)\n\n# Plot the distributions\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(normal_preds, bins=20, alpha=0.7, label='Normal Image Predictions')\nplt.title('Prediction Distribution (High Uncertainty)')\nplt.xlabel('Predicted Probability of Pneumonia')\nplt.ylabel('Frequency')\nplt.xlim(0, 1) # Keep x-axis consistent\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.hist(pneumonia_preds, bins=10, alpha=0.7, color='r', label='Pneumonia Image Predictions')\nplt.title('Prediction Distribution (Low Uncertainty)')\nplt.xlabel('Predicted Probability of Pneumonia')\nplt.xlim(0, 1) # Keep x-axis consistent\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- FIX: Re-define the variables for number of images ---\n# This ensures the variables are available in the current scope.\ntrain_normal_dir = os.path.join(train_dir, 'NORMAL')\ntrain_pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')\nnum_normal_train = len(os.listdir(train_normal_dir))\nnum_pneumonia_train = len(os.listdir(train_pneumonia_dir))\n# --- End of FIX ---\n\n\n# Step 1: Calculate Class Weights to handle data imbalance\n# Formula: weight_for_class_X = (total_samples / (num_classes * num_samples_of_class_X))\n\ntotal_train_samples = num_normal_train + num_pneumonia_train\nweight_for_0 = (1 / num_normal_train) * (total_train_samples / 2.0)\nweight_for_1 = (1 / num_pneumonia_train) * (total_train_samples / 2.0)\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f\"Weight for class 0 (NORMAL): {class_weight[0]:.2f}\")\nprint(f\"Weight for class 1 (PNEUMONIA): {class_weight[1]:.2f}\")\nprint(\"\\n--- Re-training the MC model with class weights ---\\n\")\n\n# We need to re-compile the model to reset its state before re-training\nmc_model.compile(loss='binary_crossentropy',\n                 optimizer=optimizers.RMSprop(learning_rate=2e-5),\n                 metrics=['accuracy'])\n\n# Step 2: Re-train the model, but this time passing the class_weight argument\nhistory_weighted = mc_model.fit(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=10,\n    validation_data=validation_generator,\n    validation_steps=50,\n    class_weight=class_weight  # <--- THE IMPORTANT ADDITION\n)\n\n# Save the new, improved model\nmc_model.save('pneumonia_classifier_mc_weighted_v2.keras')\nprint(\"\\nTraining with weights complete and new model saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================================================================\n# FIX 2: Re-define ALL necessary variables to make the cell independent\n# ==================================================================\n\n# --- Re-defining file paths and counts ---\nbase_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\ntrain_dir = os.path.join(base_dir, 'train')\ntrain_normal_dir = os.path.join(train_dir, 'NORMAL')\ntrain_pneumonia_dir = os.path.join(train_dir, 'PNEUMONIA')\nnum_normal_train = len(os.listdir(train_normal_dir))\nnum_pneumonia_train = len(os.listdir(train_pneumonia_dir))\n\n# --- Re-building the MC model architecture ---\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\nconv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\nconv_base.trainable = False\n\nmc_model = models.Sequential([\n    conv_base,\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])\n\n# ==================================================================\n# Original code starts here\n# ==================================================================\n\n# Step 1: Calculate Class Weights\ntotal_train_samples = num_normal_train + num_pneumonia_train\nweight_for_0 = (1 / num_normal_train) * (total_train_samples / 2.0)\nweight_for_1 = (1 / num_pneumonia_train) * (total_train_samples / 2.0)\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(f\"Weight for class 0 (NORMAL): {class_weight[0]:.2f}\")\nprint(f\"Weight for class 1 (PNEUMONIA): {class_weight[1]:.2f}\")\nprint(\"\\n--- Re-training the MC model with class weights ---\\n\")\n\n# Compile the model\nmc_model.compile(loss='binary_crossentropy',\n                 optimizer=optimizers.RMSprop(learning_rate=2e-5),\n                 metrics=['accuracy'])\n\n# Step 2: Re-train the model with class_weight\nhistory_weighted = mc_model.fit(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=10,\n    validation_data=validation_generator,\n    validation_steps=50,\n    class_weight=class_weight\n)\n\n# Save the new, improved model\nmc_model.save('pneumonia_classifier_mc_weighted_v2.keras')\nprint(\"\\nTraining with weights complete and new model saved!\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Create a data generator for the test set.\n# It's crucial that shuffle=False, so we can analyze predictions later if needed.\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False) # Do not shuffle the test data\n\n# Step 2: Evaluate the final, weighted model on the test set.\nprint(\"\\n--- Evaluating the final model on the unseen test set ---\")\ntest_loss, test_accuracy = mc_model.evaluate(test_generator)\n\nprint(f\"\\nFinal Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Final Test Loss: {test_loss:.4f}\")\n\n# Step 3: Let's get more detailed metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n# Get the ground truth labels\ny_true = test_generator.classes\n\n# Get the model's predictions\n# We'll use the standard prediction method here, not MC, for a baseline report.\ny_pred_probs = mc_model.predict(test_generator)\ny_pred = np.where(y_pred_probs > 0.5, 1, 0).flatten()\n\n# Generate and print the classification report\nprint(\"\\n--- Classification Report ---\")\nprint(classification_report(y_true, y_pred, target_names=['NORMAL (Class 0)', 'PNEUMONIA (Class 1)']))\n\n# Generate and print the confusion matrix\nprint(\"\\n--- Confusion Matrix ---\")\nprint(\"         Predicted 0   Predicted 1\")\nprint(\"Actual 0\", confusion_matrix(y_true, y_pred)[0])\nprint(\"Actual 1\", confusion_matrix(y_true, y_pred)[1])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Install Gradio library\n# The '!' tells the notebook to run this as a shell command\n!pip install gradio -q\n\nimport gradio as gr\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\n\n# Step 2: Load our best trained model\n# Make sure the filename is correct\nfinal_model = load_model('pneumonia_classifier_mc_weighted_v2.keras')\n\n# Step 3: Create a single, all-in-one prediction function for Gradio\ndef predict_and_visualize(input_image):\n    \"\"\"\n    Takes a user-uploaded image, performs MC prediction, and returns results and a plot.\n    \"\"\"\n    # Gradio provides the image as a numpy array, so we don't need to load it from a path\n    # We just need to resize and normalize it\n    img_array = np.array(input_image)\n    img_resized = np.resize(img_array, (150, 150, 3)) # Resize to our model's input size\n    img_tensor = np.expand_dims(img_resized, axis=0)\n    img_tensor = img_tensor / 255.0 # Normalize\n\n    # Perform Monte Carlo predictions\n    num_samples = 100\n    predictions = []\n    for _ in range(num_samples):\n        pred = final_model(img_tensor, training=True)\n        predictions.append(pred.numpy().flatten()[0])\n\n    # Calculate results\n    mean_prediction = np.mean(predictions)\n    std_dev = np.std(predictions)\n    confidence = (1 - std_dev) * 100\n\n    # Determine the final label\n    if mean_prediction > 0.5:\n        label = \"PNEUMONIA\"\n    else:\n        label = \"NORMAL\"\n\n    # Create the histogram plot\n    fig = plt.figure()\n    plt.hist(predictions, bins=20, alpha=0.7)\n    plt.title(f\"Prediction Distribution (Uncertainty: {std_dev:.3f})\")\n    plt.xlabel(\"Predicted Probability of Pneumonia\")\n    plt.ylabel(\"Frequency\")\n    plt.xlim(0, 1)\n    # We can't show the plot directly, but we return the figure object\n    \n    # Format the results for display\n    results = f\"Final Prediction: {label}\\n\"\n    results += f\"Confidence Score: {confidence:.2f}%\\n\"\n    results += f\"(Raw Pneumonia Probability: {mean_prediction:.3f})\"\n\n    return results, fig\n\nprint(\"Gradio installed and prediction function is ready!\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Launch the Gradio interface\ngr.Interface(fn=predict_and_visualize,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=[\"text\", \"plot\"],\n             title=\"Pneumonia Detection with Uncertainty Estimation\",\n             description=\"Upload a chest X-ray image to get a prediction. The model indicates its confidence through an uncertainty score and a prediction distribution plot.\").launch(debug=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# We will create ONE generator and use it to split the MAIN training data\n# This ignores the tiny 'val' folder and creates a proper, larger validation set.\n\ndatagen_with_split = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    validation_split=0.2  # <--- THE MAGIC PARAMETER: Reserve 20% of data for validation\n)\n\n# Now, create two generators from the SAME directory (train_dir)\n# but specify which subset to use for each.\n\nIMG_SIZE = (150, 150)\nBATCH_SIZE = 32\n\n# The main training folder\ntrain_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n\nprint(\"--- Creating new, improved data generators ---\")\n\n# Generator for the new, larger training set (80%)\ntrain_generator_new = datagen_with_split.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training'  # Specify this is the training subset\n)\n\n# Generator for the new, larger validation set (20%)\nvalidation_generator_new = datagen_with_split.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation' # Specify this is the validation subset\n)\n\nprint(\"\\n--- Re-calculating class weights for the new training split ---\")\n# We need to recalculate weights based on the new 80% training split\n# The generator tells us the new counts\nnum_normal_new = np.sum(train_generator_new.classes == 0)\nnum_pneumonia_new = np.sum(train_generator_new.classes == 1)\ntotal_new_train = num_normal_new + num_pneumonia_new\n\nweight_for_0_new = (1 / num_normal_new) * (total_new_train / 2.0)\nweight_for_1_new = (1 / num_pneumonia_new) * (total_new_train / 2.0)\nclass_weight_new = {0: weight_for_0_new, 1: weight_for_1_new}\n\nprint(f\"New training samples: {total_new_train}\")\nprint(f\"New validation samples: {validation_generator_new.n}\")\nprint(f\"New weight for NORMAL: {class_weight_new[0]:.2f}\")\nprint(f\"New weight for PNEUMONIA: {class_weight_new[1]:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:34:04.074958Z","iopub.execute_input":"2025-12-05T17:34:04.075805Z","iopub.status.idle":"2025-12-05T17:34:09.360647Z","shell.execute_reply.started":"2025-12-05T17:34:04.075779Z","shell.execute_reply":"2025-12-05T17:34:09.359842Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 17:34:04.352032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764956044.373515    1398 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764956044.379975    1398 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"--- Creating new, improved data generators ---\nFound 4173 images belonging to 2 classes.\nFound 1043 images belonging to 2 classes.\n\n--- Re-calculating class weights for the new training split ---\nNew training samples: 4173\nNew validation samples: 1043\nNew weight for NORMAL: 1.94\nNew weight for PNEUMONIA: 0.67\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\n# --- Re-building the MC model architecture ---\nconv_base_new = VGG16(weights='imagenet',\n                      include_top=False,\n                      input_shape=(150, 150, 3))\nconv_base_new.trainable = False\n\nmc_model_new = models.Sequential([\n    conv_base_new,\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])\n\n# --- Compile the new model ---\nmc_model_new.compile(loss='binary_crossentropy',\n                     optimizer=optimizers.RMSprop(learning_rate=2e-5),\n                     metrics=['accuracy'])\n\nprint(\"--- Starting final training with improved data generators ---\")\n\n# --- Train the model with the NEW generators and NEW class weights ---\nhistory_final = mc_model_new.fit(\n    train_generator_new,\n    steps_per_epoch=100,  # We can keep this at 100\n    epochs=15,  # Let's train for a bit longer (15 epochs) as we have more data\n    validation_data=validation_generator_new,\n    validation_steps=50, # We can keep this at 50\n    class_weight=class_weight_new\n)\n\n# --- Save the final, most powerful model ---\nmc_model_new.save('pneumonia_classifier_final_v3.keras')\nprint(\"\\nFinal training complete! The best model yet has been saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:35:22.303793Z","iopub.execute_input":"2025-12-05T17:35:22.304794Z","iopub.status.idle":"2025-12-05T17:45:37.350527Z","shell.execute_reply.started":"2025-12-05T17:35:22.304764Z","shell.execute_reply":"2025-12-05T17:45:37.349590Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1764956122.629303    1398 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1764956122.629883    1398 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"--- Starting final training with improved data generators ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1764956126.045772    1466 service.cc:148] XLA service 0x79f478003900 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1764956126.045807    1466 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1764956126.045811    1466 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1764956126.349740    1466 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/100\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.6016 - loss: 0.8189 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764956132.953988    1466 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 617ms/step - accuracy: 0.6664 - loss: 0.6236 - val_accuracy: 0.8150 - val_loss: 0.4083\nEpoch 2/15\n\u001b[1m  1/100\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8750 - loss: 0.3487","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 238ms/step - accuracy: 0.8667 - loss: 0.3461 - val_accuracy: 0.8715 - val_loss: 0.3409\nEpoch 3/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 523ms/step - accuracy: 0.8814 - loss: 0.3235 - val_accuracy: 0.8878 - val_loss: 0.2885\nEpoch 4/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 247ms/step - accuracy: 0.8963 - loss: 0.2563 - val_accuracy: 0.8658 - val_loss: 0.2995\nEpoch 5/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 535ms/step - accuracy: 0.9016 - loss: 0.2499 - val_accuracy: 0.9070 - val_loss: 0.2284\nEpoch 6/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 245ms/step - accuracy: 0.9081 - loss: 0.2398 - val_accuracy: 0.8888 - val_loss: 0.2555\nEpoch 7/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 528ms/step - accuracy: 0.9121 - loss: 0.2308 - val_accuracy: 0.9003 - val_loss: 0.2340\nEpoch 8/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 251ms/step - accuracy: 0.8952 - loss: 0.2458 - val_accuracy: 0.8907 - val_loss: 0.2608\nEpoch 9/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 533ms/step - accuracy: 0.9217 - loss: 0.2054 - val_accuracy: 0.8782 - val_loss: 0.2621\nEpoch 10/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 247ms/step - accuracy: 0.9069 - loss: 0.2119 - val_accuracy: 0.8754 - val_loss: 0.2747\nEpoch 11/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 531ms/step - accuracy: 0.9276 - loss: 0.1867 - val_accuracy: 0.9051 - val_loss: 0.2429\nEpoch 12/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 249ms/step - accuracy: 0.9314 - loss: 0.1704 - val_accuracy: 0.9118 - val_loss: 0.2192\nEpoch 13/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 530ms/step - accuracy: 0.9318 - loss: 0.1780 - val_accuracy: 0.9233 - val_loss: 0.2001\nEpoch 14/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 252ms/step - accuracy: 0.9150 - loss: 0.2220 - val_accuracy: 0.9089 - val_loss: 0.2147\nEpoch 15/15\n\u001b[1m100/100\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 531ms/step - accuracy: 0.9305 - loss: 0.1787 - val_accuracy: 0.9195 - val_loss: 0.1946\n\nFinal training complete! The best model yet has been saved.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Step 1: Create a data generator for the test set (if not already created in this session)\ntest_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/test'\ntest_datagen = ImageDataGenerator(rescale=1./255) # Just rescale, no augmentation\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False)\n\n# Step 2: Evaluate the FINAL model on the unseen test set\nprint(\"\\n--- Evaluating the FINAL, IMPROVED model on the unseen test set ---\")\n# Make sure to use mc_model_new, our latest and greatest model\ntest_loss, test_accuracy = mc_model_new.evaluate(test_generator)\n\nprint(f\"\\nFinal Test Accuracy: {test_accuracy * 100:.2f}%\")\nprint(f\"Final Test Loss: {test_loss:.4f}\")\n\n# Step 3: Generate detailed metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\ny_true = test_generator.classes\ny_pred_probs = mc_model_new.predict(test_generator)\ny_pred = np.where(y_pred_probs > 0.5, 1, 0).flatten()\n\nprint(\"\\n--- Classification Report ---\")\nprint(classification_report(y_true, y_pred, target_names=['NORMAL (Class 0)', 'PNEUMONIA (Class 1)']))\n\nprint(\"\\n--- Confusion Matrix ---\")\nprint(confusion_matrix(y_true, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure all necessary libraries are imported for this new session\nimport gradio as gr\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nprint(\"--- Preparing the Final Demo ---\")\n\n# Step 1: Load our BEST and FINAL trained model\ntry:\n    final_model = load_model('pneumonia_classifier_final_v3.keras')\n    print(\"Model 'pneumonia_classifier_final_v3.keras' loaded successfully!\")\nexcept Exception as e:\n    print(f\"Error loading model: {e}\")\n    print(\"Please ensure you have run the final training cell to generate the model file.\")\n\n# Step 2: Create the final, all-in-one prediction function\ndef predict_final(input_image):\n    \"\"\"\n    Takes a user-uploaded image, performs MC prediction with the FINAL model,\n    and returns polished results and a plot.\n    \"\"\"\n    if input_image is None:\n        return \"Please upload an image.\", None\n\n    # Gradio provides a PIL image, convert to numpy array and resize\n    img = np.array(input_image.resize((150, 150)))\n    \n    # Ensure image is 3-channel (RGB)\n    if img.ndim == 2: # If it's grayscale\n        img = np.stack((img,)*3, axis=-1)\n    \n    img_tensor = np.expand_dims(img, axis=0)\n    img_tensor = img_tensor / 255.0  # Normalize\n\n    # --- Perform Monte Carlo predictions ---\n    num_samples = 100\n    predictions = []\n    for _ in range(num_samples):\n        pred = final_model(img_tensor, training=True) # Enable dropout for uncertainty\n        predictions.append(pred.numpy().flatten()[0])\n\n    # --- Calculate and interpret results ---\n    mean_prediction = np.mean(predictions)\n    std_dev = np.std(predictions)\n    \n    # We define confidence differently now: as certainty in the chosen class\n    if mean_prediction > 0.5:\n        label = \"PNEUMONIA\"\n        confidence = mean_prediction * 100\n    else:\n        label = \"NORMAL\"\n        confidence = (1 - mean_prediction) * 100\n    \n    uncertainty_score = std_dev * 100 # As a percentage\n\n    # --- Create the histogram plot ---\n    fig = plt.figure(figsize=(8, 5))\n    plt.hist(predictions, bins=20, alpha=0.8, color='#007BFF')\n    plt.title(\"Prediction Distribution\", fontsize=16)\n    plt.xlabel(\"Model's Prediction (Probability of Pneumonia)\", fontsize=12)\n    plt.ylabel(\"Frequency (out of 100 runs)\", fontsize=12)\n    plt.xlim(0, 1)\n    plt.axvline(x=mean_prediction, color='r', linestyle='--', label=f'Average: {mean_prediction:.2f}')\n    plt.legend()\n    plt.grid(alpha=0.3)\n    \n    # --- Format the final results for display ---\n    results = {\n        \"Final Prediction\": label,\n        f\"Confidence in '{label}'\": f\"{confidence:.2f}%\",\n        \"Uncertainty Score\": f\"{uncertainty_score:.2f}% (Lower is better)\"\n    }\n\n    return results, fig\n\nprint(\"Final prediction function is ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:45:51.844567Z","iopub.execute_input":"2025-12-05T17:45:51.844844Z","iopub.status.idle":"2025-12-05T17:45:54.376630Z","shell.execute_reply.started":"2025-12-05T17:45:51.844822Z","shell.execute_reply":"2025-12-05T17:45:54.375945Z"}},"outputs":[{"name":"stdout","text":"--- Preparing the Final Demo ---\nModel 'pneumonia_classifier_final_v3.keras' loaded successfully!\nFinal prediction function is ready!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Launch the final, professional Gradio interface (FIXED VERSION) ---\n\n# FIX 2: Define the exact path where the examples are located\nexample_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/test/'\n\ndemo = gr.Interface(\n    fn=predict_final,\n    inputs=gr.Image(type=\"pil\", label=\"Upload Chest X-ray Image\"),\n    outputs=[\n        # FIX 1: Change the output type to a simple Textbox to match our function's output\n        gr.Textbox(label=\"Analysis Results\"),\n        gr.Plot(label=\"Prediction Distribution & Uncertainty\")\n    ],\n    title=\"ðŸ©º AI-Powered Pneumonia Detection with Uncertainty Estimation\",\n    description=\"\"\"\n    **Welcome! This is a proof-of-concept tool, not for medical use.**\n    Upload a chest X-ray to see the model's prediction. The system uses a deep learning model (VGG16) and Monte Carlo Dropout to not only classify the image but also to estimate its own uncertainty.\n    - **High Confidence & Low Uncertainty:** The model is sure of its decision.\n    - **Low Confidence & High Uncertainty:** The model is unsure and suggests the case might be complex or unusual, requiring expert review.\n    \"\"\",\n    article=\"**Developed by:** [Your Name Here] - **Model Version:** v3.0\",\n    examples=[\n        [example_path + 'NORMAL/NORMAL2-IM-1427-0001.jpeg'],\n        [example_path + 'PNEUMONIA/person100_bacteria_475.jpeg']\n    ],\n    allow_flagging='never'\n)\n\n# FIX 2 (continued): Add the allowed_paths parameter to the launch() function\ndemo.launch(debug=True, allowed_paths=[example_path])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T17:46:01.396135Z","iopub.execute_input":"2025-12-05T17:46:01.397191Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gradio/interface.py:425: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://54dde5ec503767e295.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://54dde5ec503767e295.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 626, in process_events\n    response = await route_utils.call_process_api(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 350, in call_process_api\n    output = await app.get_blocks().process_api(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2231, in process_api\n    inputs = await self.preprocess_data(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1877, in preprocess_data\n    inputs_cached = await processing_utils.async_move_files_to_cache(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 676, in async_move_files_to_cache\n    return await client_utils.async_traverse(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio_client/utils.py\", line 1198, in async_traverse\n    return await func(json_obj)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 647, in _move_to_cache\n    _check_allowed(payload.path, check_in_upload_folder)\n  File \"/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py\", line 592, in _check_allowed\n    raise InvalidPathError(msg)\ngradio.exceptions.InvalidPathError: Cannot move /kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL/NORMAL2-IM-1427-0001.jpeg to the gradio cache dir because it was not uploaded by a user.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}